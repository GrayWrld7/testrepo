{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrayWrld7/testrepo/blob/master/PY0101EN_5_2_API_2_edited.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8EywIJWDeft"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
        "</center>\n",
        "\n",
        "# Watson Speech to Text Translator\n",
        "\n",
        "Estimated time needed: **25** minutes\n",
        "\n",
        "## Objectives\n",
        "\n",
        "After completing this lab you will be able to:\n",
        "\n",
        "*   Operate a Speech to Text Translator through an API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDIl4j56Defw"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "<p>In this notebook, you will learn to convert an audio file of an English speaker to text using a Speech to Text API. Then, you will translate the English version to a Spanish version using a Language Translator API. <b>Note:</b> You must obtain the API keys and endpoints to complete the lab.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywk5kvQPDefy"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "<h2>Table of Contents</h2>\n",
        "<ul>\n",
        "    <li><a href=\"https://#ref0\">Speech To Text</a></li>\n",
        "    <li><a href=\"https://#ref1\">Language Translator</a></li>\n",
        "    <li><a href=\"https://#ref2\">Exercise</a></li>\n",
        "</ul>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_zUpVs5QDefz",
        "outputId": "9ec3ab0b-d051-4671-9b20-da39aaf2c28d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ibm_watson\n",
            "  Downloading ibm-watson-5.3.0.tar.gz (412 kB)\n",
            "     |████████████████████████████████| 412 kB 10.4 MB/s            \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: wget in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (3.2)\n",
            "Collecting websocket-client==1.1.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "     |████████████████████████████████| 68 kB 8.5 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ibm_watson) (2.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ibm_watson) (2.8.2)\n",
            "Collecting ibm-cloud-sdk-core==3.*,>=3.3.6\n",
            "  Downloading ibm-cloud-sdk-core-3.13.2.tar.gz (49 kB)\n",
            "     |████████████████████████████████| 49 kB 10.4 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: urllib3<2.0.0,>=1.26.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm_watson) (1.26.7)\n",
            "Collecting PyJWT<3.0.0,>=2.0.1\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-dateutil>=2.5.3->ibm_watson) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm_watson) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm_watson) (3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm_watson) (2.0.8)\n",
            "Building wheels for collected packages: ibm-watson, ibm-cloud-sdk-core\n",
            "  Building wheel for ibm-watson (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for ibm-watson: filename=ibm_watson-5.3.0-py3-none-any.whl size=408872 sha256=bb8c611bff17a3a19bffd132ce6ddb8819c89214e339af8d45c3a0eb8c48b4b9\n",
            "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/21/d9/82/4ce5b94730bc4f1f7b4c6384f72964b9b8f79fcc125bb8085c\n",
            "  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.13.2-py3-none-any.whl size=83241 sha256=d4abaa29be8adb0fbe60c3c8ec29b073e9efb726ad47146060c77fc9ba4cd684\n",
            "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/f0/0d/5c/0c26fcc2db712e8d270e52f7c9f6d8abe33ca79ec29438aa14\n",
            "Successfully built ibm-watson ibm-cloud-sdk-core\n",
            "Installing collected packages: PyJWT, websocket-client, ibm-cloud-sdk-core, ibm-watson\n",
            "Successfully installed PyJWT-2.3.0 ibm-cloud-sdk-core-3.13.2 ibm-watson-5.3.0 websocket-client-1.1.0\n"
          ]
        }
      ],
      "source": [
        "#you will need the following library \n",
        "!pip install ibm_watson wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "_zm-OiFQDef2"
      },
      "source": [
        "<h2 id=\"ref0\">Speech to Text</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAQSIu3lDef3"
      },
      "source": [
        "<p>First we import <code>SpeechToTextV1</code> from <code>ibm_watson</code>. For more information on the API, please click on this <a href=\"https://cloud.ibm.com/apidocs/speech-to-text?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01&code=python\">link</a>.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xlTbwvumDef4"
      },
      "outputs": [],
      "source": [
        "from ibm_watson import SpeechToTextV1 \n",
        "import json\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhxkCFSADef5"
      },
      "outputs": [],
      "source": [
        "from ibm_watson import SpeechToTextV1\n",
        "import json\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkxdXwXLDef6"
      },
      "source": [
        "<p>The service endpoint is based on the location of the service instance, we store the information in the variable URL. To find out which URL to use, view the service credentials and paste the url here.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ho1gQOIDef8"
      },
      "outputs": [],
      "source": [
        "url_s2t = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2rvJSnqDef9"
      },
      "outputs": [],
      "source": [
        "url_s2t=\"https://api.eu-de.speech-to-text.watson.cloud.ibm.com/instances/1568afac-2a9b-4c8f-9ff4-39e9412805e3\" #service endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KePvOwKDef-"
      },
      "source": [
        "<p>You require an API key, and you can obtain the key on the <a href=\"https://cloud.ibm.com/resources?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01\">Dashboard </a>.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "3Lu2HUFBDef-"
      },
      "outputs": [],
      "source": [
        "iam_apikey_s2t = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5yRr61YDef_"
      },
      "outputs": [],
      "source": [
        "iam_apikey_s2t=\"5z3y6MJrujuqpiCB4sEYsGe8IR_X_Ph6Yl1y41Jl9eKr\" #API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4TgIz2SDegA"
      },
      "source": [
        "<p>You create a <a href=\"http://watson-developer-cloud.github.io/python-sdk/v0.25.0/apis/watson_developer_cloud.speech_to_text_v1.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01\">Speech To Text Adapter object</a> the parameters are the endpoint and API key.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWS5ZwXxDegA"
      },
      "outputs": [],
      "source": [
        "authenticator = IAMAuthenticator(iam_apikey_s2t)\n",
        "s2t = SpeechToTextV1(authenticator=authenticator)\n",
        "s2t.set_service_url(url_s2t)\n",
        "s2t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86dsaL1rDegB",
        "outputId": "1cd1fc39-5075-4ffd-8c95-66d0ab29c5aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ibm_watson.speech_to_text_v1_adapter.SpeechToTextV1Adapter at 0x7ff8716704d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Speech To Text Adapter object\n",
        "authenticator=IAMAuthenticator(iam_apikey_s2t)\n",
        "s2t=SpeechToTextV1(authenticator=authenticator) #adapter object-->parameter API key\n",
        "s2t.set_service_url(url_s2t) #adapter object-->parameter endpoint (service location aka \"url\")\n",
        "s2t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp_ySSpqDegB",
        "outputId": "33fc55dd-317f-4b23-ef20-b02d960f74da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['DEFAULT_SERVICE_NAME',\n",
              " 'DEFAULT_SERVICE_URL',\n",
              " 'ERROR_MSG_DISABLE_SSL',\n",
              " 'SDK_NAME',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_build_user_agent',\n",
              " '_convert_list',\n",
              " '_convert_model',\n",
              " '_encode_path_vars',\n",
              " '_get_system_info',\n",
              " '_set_user_agent_header',\n",
              " 'add_audio',\n",
              " 'add_corpus',\n",
              " 'add_grammar',\n",
              " 'add_word',\n",
              " 'add_words',\n",
              " 'authenticator',\n",
              " 'check_job',\n",
              " 'check_jobs',\n",
              " 'configure_service',\n",
              " 'create_acoustic_model',\n",
              " 'create_job',\n",
              " 'create_language_model',\n",
              " 'default_headers',\n",
              " 'delete_acoustic_model',\n",
              " 'delete_audio',\n",
              " 'delete_corpus',\n",
              " 'delete_grammar',\n",
              " 'delete_job',\n",
              " 'delete_language_model',\n",
              " 'delete_user_data',\n",
              " 'delete_word',\n",
              " 'disable_retries',\n",
              " 'disable_ssl_verification',\n",
              " 'enable_gzip_compression',\n",
              " 'enable_retries',\n",
              " 'encode_path_vars',\n",
              " 'get_acoustic_model',\n",
              " 'get_audio',\n",
              " 'get_authenticator',\n",
              " 'get_corpus',\n",
              " 'get_enable_gzip_compression',\n",
              " 'get_grammar',\n",
              " 'get_http_client',\n",
              " 'get_language_model',\n",
              " 'get_model',\n",
              " 'get_word',\n",
              " 'http_adapter',\n",
              " 'http_client',\n",
              " 'http_config',\n",
              " 'jar',\n",
              " 'list_acoustic_models',\n",
              " 'list_audio',\n",
              " 'list_corpora',\n",
              " 'list_grammars',\n",
              " 'list_language_models',\n",
              " 'list_models',\n",
              " 'list_words',\n",
              " 'prepare_request',\n",
              " 'recognize',\n",
              " 'recognize_using_websocket',\n",
              " 'register_callback',\n",
              " 'reset_acoustic_model',\n",
              " 'reset_language_model',\n",
              " 'retry_config',\n",
              " 'send',\n",
              " 'service_url',\n",
              " 'set_default_headers',\n",
              " 'set_disable_ssl_verification',\n",
              " 'set_enable_gzip_compression',\n",
              " 'set_http_client',\n",
              " 'set_http_config',\n",
              " 'set_service_url',\n",
              " 'train_acoustic_model',\n",
              " 'train_language_model',\n",
              " 'unregister_callback',\n",
              " 'upgrade_acoustic_model',\n",
              " 'upgrade_language_model',\n",
              " 'user_agent_header']"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(s2t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C72IWcKLDegD",
        "outputId": "7bf93bfa-0249-4405-88ee-ea5be54f5228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://api.eu-de.speech-to-text.watson.cloud.ibm.com/instances/1568afac-2a9b-4c8f-9ff4-39e9412805e3'"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s2t.service_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACgkzsDQDegD"
      },
      "source": [
        "<p>Lets download the audio file that we will use to convert into text.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5UFYXMHDegD"
      },
      "outputs": [],
      "source": [
        "!wget -O PolynomialRegressionandPipelines.mp3  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/PolynomialRegressionandPipelines.mp3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZzMx1ryDegD",
        "outputId": "3a6673e5-be80-4988-90a2-b3f8f48aca14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-13 16:27:37--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/PolynomialRegressionandPipelines.mp3\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4234179 (4.0M) [audio/mpeg]\n",
            "Saving to: ‘PolynomialRegressionandPipelines.mp3’\n",
            "\n",
            "PolynomialRegressio 100%[===================>]   4.04M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-12-13 16:27:37 (124 MB/s) - ‘PolynomialRegressionandPipelines.mp3’ saved [4234179/4234179]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O PolynomialRegressionandPipelines.mp3 https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/PolynomialRegressionandPipelines.mp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Fqv9gKDegE"
      },
      "source": [
        "<p>We have the path of the .wav file we would like to convert to text</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zNi9VS17DegE"
      },
      "outputs": [],
      "source": [
        "filename='PolynomialRegressionandPipelines.mp3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsUznRMVDegF",
        "outputId": "b1332b79-2767-445e-f391-b7efcc301fc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'PolynomialRegressionandPipelines.mp3'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename=\"PolynomialRegressionandPipelines.mp3\"\n",
        "filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA6IEF3PDegG"
      },
      "source": [
        "<p>We create the file object <code>wav</code> with the wav file using <code>open</code>. We set the <code>mode</code> to  \"rb\" ,  this is similar to read mode, but it ensures the file is in binary mode. We use the method <code>recognize</code> to return the recognized text. The parameter <code>audio</code> is the file object <code>wav</code>, the parameter <code>content_type</code> is the format of the audio file.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "p_BXidUQDegH"
      },
      "outputs": [],
      "source": [
        "with open(filename, mode=\"rb\")  as wav:\n",
        "    response = s2t.recognize(audio=wav, content_type='audio/mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_YACwalDegH"
      },
      "outputs": [],
      "source": [
        "with open(filename,\"rb\") as wav:\n",
        "    response=s2t.recognize(audio=wav, content_type=\"audio/mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVMX6tbEDegH"
      },
      "source": [
        "<p>The attribute result contains a dictionary that includes the translation:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkBx2q3mDegI"
      },
      "outputs": [],
      "source": [
        "response.result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRIThU_eDegI",
        "outputId": "f19433d5-40b0-4918-c691-eb4cd8aef33d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': {'result_index': 0,\n",
              "  'results': [{'final': True,\n",
              "    'alternatives': [{'transcript': 'in this video we will cover polynomial regression and pipelines ',\n",
              "      'confidence': 0.94}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': \"what do we do when a linear model is not the best fit for our data let's look into another type of regression model the polynomial regression we transform our data into a polynomial then use linear regression to fit the parameters that we will discuss pipelines pipelines are way to simplify your code \",\n",
              "      'confidence': 0.9}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': \"polynomial regression is a special case of the general linear regression this method is beneficial for describing curvilinear relationships what is a curvilinear relationship it's what you get by squaring or setting higher order terms of the predictor variables in the model transforming the data the model can be quadratic which means the predictor variable in the model is squared we use a bracket to indicated as an exponent this is the second order polynomial regression with a figure representing the function \",\n",
              "      'confidence': 0.95}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': 'the model can be cubic which means the predictor variable is cute this is the third order polynomial regression we see by examining the figure that the function has more variation ',\n",
              "      'confidence': 0.95}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': \"there also exists higher order polynomial regressions when a good fit hasn't been achieved by second or third order we can see in figures how much the graphs change when we change the order of the polynomial regression the degree of the regression makes a big difference and can result in a better fit if you pick the right value in all cases the relationship between the variable in the parameter is always linear \",\n",
              "      'confidence': 0.91}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': \"let's look at an example from our data we generate a polynomial regression model \",\n",
              "      'confidence': 0.89}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': 'in python we do this by using the poly fit function in this example we develop a third order polynomial regression model base we can print out the model symbolic form for the model is given by the following expression ',\n",
              "      'confidence': 0.92}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': \"negative one point five five seven X. one cute plus two hundred four point eight X. one squared plus eight thousand nine hundred sixty five X. one plus one point three seven times ten to the power of five we can also have multi dimensional polynomial linear regression the expression can get complicated here are just some of the terms for two dimensional second order polynomial none pies poly fit function cannot perform this type of regression we use the preprocessing librarian scikit learn to create a polynomial feature object the constructor takes the degree of the polynomial as a parameter then we transform the features into a polynomial feature with the fit underscore transform method let's do a more intuitive example \",\n",
              "      'confidence': 0.9}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': 'consider the feature shown here applying the method we transform the data we now have a new set of features that are transformed version of our original features as that I mention of the data gets larger we may want to normalize multiple features as scikit learn instead we can use the preprocessing module to simplify many tasks for example we can standardize each feature simultaneously we import standard scaler we train the object fit the scale object then transform the data into a new data frame on a rate X. underscore scale there are more normalization methods available in the pre processing library as well as other transformations we can simplify our code by using a pipeline library there are many steps to getting a prediction for example normalization polynomial transform and linear regression we simplify the process using a pipeline ',\n",
              "      'confidence': 0.9}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': 'pipeline sequentially perform a series of transformations the last step carries out a prediction first we import all the modules we need then we import the library pipeline we create a list of topples the first element in the topple contains the name of the estimator model the second element contains model constructor we input the list in the pipeline constructor we now have a pipeline object we can train the pipeline by applying the train method to the pipeline object we can also produce a prediction as well ',\n",
              "      'confidence': 0.89}]},\n",
              "   {'final': True,\n",
              "    'alternatives': [{'transcript': 'the method normalizes the data performs a polynomial transform then outputs a prediction ',\n",
              "      'confidence': 0.88}]}]},\n",
              " 'headers': {'Server': 'watson-gateway', 'session-name': 'BRYSLRRKLSEKMCQY-en-US_BroadbandModel', 'x-xss-protection': '1', 'x-content-type-options': 'nosniff', 'x-frame-options': 'DENY', 'Content-Security-Policy': \"default-src 'none'\", 'Content-Type': 'application/json', 'strict-transport-security': 'max-age=31536000; includeSubDomains;', 'x-dp-watson-tran-id': '298b930e-33ab-4090-9c86-cfdf76383b89', 'x-request-id': '298b930e-33ab-4090-9c86-cfdf76383b89', 'x-global-transaction-id': '298b930e-33ab-4090-9c86-cfdf76383b89', 'X-EdgeConnect-MidMile-RTT': '3', 'X-EdgeConnect-Origin-MEX-Latency': '5295', 'Date': 'Mon, 13 Dec 2021 16:47:22 GMT', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive, Transfer-Encoding'},\n",
              " 'status_code': 200}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vars(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DsAdjhyDegJ",
        "outputId": "40518f74-3327-483c-b133-c571ded0a7fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_to_dict',\n",
              " 'get_headers',\n",
              " 'get_result',\n",
              " 'get_status_code',\n",
              " 'headers',\n",
              " 'result',\n",
              " 'status_code']"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ7WuHnkDegJ",
        "outputId": "a92a6d6b-2f5f-4541-ce1e-bda649955664"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result_index': 0,\n",
              " 'results': [{'final': True,\n",
              "   'alternatives': [{'transcript': 'in this video we will cover polynomial regression and pipelines ',\n",
              "     'confidence': 0.94}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': \"what do we do when a linear model is not the best fit for our data let's look into another type of regression model the polynomial regression we transform our data into a polynomial then use linear regression to fit the parameters that we will discuss pipelines pipelines are way to simplify your code \",\n",
              "     'confidence': 0.9}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': \"polynomial regression is a special case of the general linear regression this method is beneficial for describing curvilinear relationships what is a curvilinear relationship it's what you get by squaring or setting higher order terms of the predictor variables in the model transforming the data the model can be quadratic which means the predictor variable in the model is squared we use a bracket to indicated as an exponent this is the second order polynomial regression with a figure representing the function \",\n",
              "     'confidence': 0.95}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': 'the model can be cubic which means the predictor variable is cute this is the third order polynomial regression we see by examining the figure that the function has more variation ',\n",
              "     'confidence': 0.95}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': \"there also exists higher order polynomial regressions when a good fit hasn't been achieved by second or third order we can see in figures how much the graphs change when we change the order of the polynomial regression the degree of the regression makes a big difference and can result in a better fit if you pick the right value in all cases the relationship between the variable in the parameter is always linear \",\n",
              "     'confidence': 0.91}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': \"let's look at an example from our data we generate a polynomial regression model \",\n",
              "     'confidence': 0.89}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': 'in python we do this by using the poly fit function in this example we develop a third order polynomial regression model base we can print out the model symbolic form for the model is given by the following expression ',\n",
              "     'confidence': 0.92}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': \"negative one point five five seven X. one cute plus two hundred four point eight X. one squared plus eight thousand nine hundred sixty five X. one plus one point three seven times ten to the power of five we can also have multi dimensional polynomial linear regression the expression can get complicated here are just some of the terms for two dimensional second order polynomial none pies poly fit function cannot perform this type of regression we use the preprocessing librarian scikit learn to create a polynomial feature object the constructor takes the degree of the polynomial as a parameter then we transform the features into a polynomial feature with the fit underscore transform method let's do a more intuitive example \",\n",
              "     'confidence': 0.9}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': 'consider the feature shown here applying the method we transform the data we now have a new set of features that are transformed version of our original features as that I mention of the data gets larger we may want to normalize multiple features as scikit learn instead we can use the preprocessing module to simplify many tasks for example we can standardize each feature simultaneously we import standard scaler we train the object fit the scale object then transform the data into a new data frame on a rate X. underscore scale there are more normalization methods available in the pre processing library as well as other transformations we can simplify our code by using a pipeline library there are many steps to getting a prediction for example normalization polynomial transform and linear regression we simplify the process using a pipeline ',\n",
              "     'confidence': 0.9}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': 'pipeline sequentially perform a series of transformations the last step carries out a prediction first we import all the modules we need then we import the library pipeline we create a list of topples the first element in the topple contains the name of the estimator model the second element contains model constructor we input the list in the pipeline constructor we now have a pipeline object we can train the pipeline by applying the train method to the pipeline object we can also produce a prediction as well ',\n",
              "     'confidence': 0.89}]},\n",
              "  {'final': True,\n",
              "   'alternatives': [{'transcript': 'the method normalizes the data performs a polynomial transform then outputs a prediction ',\n",
              "     'confidence': 0.88}]}]}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BaB8f5XDegK",
        "outputId": "7370f3f8-1230-4e28-83e7-71f5227582c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['result_index', 'results'])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.result.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjdpbDytDegL",
        "outputId": "b87c700e-a2b1-4f1b-b162-d7dd8e54e49c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values([0, [{'final': True, 'alternatives': [{'transcript': 'in this video we will cover polynomial regression and pipelines ', 'confidence': 0.94}]}, {'final': True, 'alternatives': [{'transcript': \"what do we do when a linear model is not the best fit for our data let's look into another type of regression model the polynomial regression we transform our data into a polynomial then use linear regression to fit the parameters that we will discuss pipelines pipelines are way to simplify your code \", 'confidence': 0.9}]}, {'final': True, 'alternatives': [{'transcript': \"polynomial regression is a special case of the general linear regression this method is beneficial for describing curvilinear relationships what is a curvilinear relationship it's what you get by squaring or setting higher order terms of the predictor variables in the model transforming the data the model can be quadratic which means the predictor variable in the model is squared we use a bracket to indicated as an exponent this is the second order polynomial regression with a figure representing the function \", 'confidence': 0.95}]}, {'final': True, 'alternatives': [{'transcript': 'the model can be cubic which means the predictor variable is cute this is the third order polynomial regression we see by examining the figure that the function has more variation ', 'confidence': 0.95}]}, {'final': True, 'alternatives': [{'transcript': \"there also exists higher order polynomial regressions when a good fit hasn't been achieved by second or third order we can see in figures how much the graphs change when we change the order of the polynomial regression the degree of the regression makes a big difference and can result in a better fit if you pick the right value in all cases the relationship between the variable in the parameter is always linear \", 'confidence': 0.91}]}, {'final': True, 'alternatives': [{'transcript': \"let's look at an example from our data we generate a polynomial regression model \", 'confidence': 0.89}]}, {'final': True, 'alternatives': [{'transcript': 'in python we do this by using the poly fit function in this example we develop a third order polynomial regression model base we can print out the model symbolic form for the model is given by the following expression ', 'confidence': 0.92}]}, {'final': True, 'alternatives': [{'transcript': \"negative one point five five seven X. one cute plus two hundred four point eight X. one squared plus eight thousand nine hundred sixty five X. one plus one point three seven times ten to the power of five we can also have multi dimensional polynomial linear regression the expression can get complicated here are just some of the terms for two dimensional second order polynomial none pies poly fit function cannot perform this type of regression we use the preprocessing librarian scikit learn to create a polynomial feature object the constructor takes the degree of the polynomial as a parameter then we transform the features into a polynomial feature with the fit underscore transform method let's do a more intuitive example \", 'confidence': 0.9}]}, {'final': True, 'alternatives': [{'transcript': 'consider the feature shown here applying the method we transform the data we now have a new set of features that are transformed version of our original features as that I mention of the data gets larger we may want to normalize multiple features as scikit learn instead we can use the preprocessing module to simplify many tasks for example we can standardize each feature simultaneously we import standard scaler we train the object fit the scale object then transform the data into a new data frame on a rate X. underscore scale there are more normalization methods available in the pre processing library as well as other transformations we can simplify our code by using a pipeline library there are many steps to getting a prediction for example normalization polynomial transform and linear regression we simplify the process using a pipeline ', 'confidence': 0.9}]}, {'final': True, 'alternatives': [{'transcript': 'pipeline sequentially perform a series of transformations the last step carries out a prediction first we import all the modules we need then we import the library pipeline we create a list of topples the first element in the topple contains the name of the estimator model the second element contains model constructor we input the list in the pipeline constructor we now have a pipeline object we can train the pipeline by applying the train method to the pipeline object we can also produce a prediction as well ', 'confidence': 0.89}]}, {'final': True, 'alternatives': [{'transcript': 'the method normalizes the data performs a polynomial transform then outputs a prediction ', 'confidence': 0.88}]}]])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.result.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5eQqyeeDegM",
        "outputId": "13cf920c-2028-4b00-d619-c345d680bc85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ibm_cloud_sdk_core.detailed_response.DetailedResponse"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usmS_whlDegM"
      },
      "outputs": [],
      "source": [
        "from pandas import json_normalize\n",
        "\n",
        "json_normalize(response.result['results'],\"alternatives\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6rQniSIDegM",
        "outputId": "b1eb47b7-f9e6-43c9-a97c-7a352ceaca34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transcript</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in this video we will cover polynomial regress...</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what do we do when a linear model is not the b...</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>polynomial regression is a special case of the...</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the model can be cubic which means the predict...</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>there also exists higher order polynomial regr...</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>let's look at an example from our data we gene...</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>in python we do this by using the poly fit fun...</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>negative one point five five seven X. one cute...</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>consider the feature shown here applying the m...</td>\n",
              "      <td>0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pipeline sequentially perform a series of tran...</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>the method normalizes the data performs a poly...</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           transcript  confidence\n",
              "0   in this video we will cover polynomial regress...        0.94\n",
              "1   what do we do when a linear model is not the b...        0.90\n",
              "2   polynomial regression is a special case of the...        0.95\n",
              "3   the model can be cubic which means the predict...        0.95\n",
              "4   there also exists higher order polynomial regr...        0.91\n",
              "5   let's look at an example from our data we gene...        0.89\n",
              "6   in python we do this by using the poly fit fun...        0.92\n",
              "7   negative one point five five seven X. one cute...        0.90\n",
              "8   consider the feature shown here applying the m...        0.90\n",
              "9   pipeline sequentially perform a series of tran...        0.89\n",
              "10  the method normalizes the data performs a poly...        0.88"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pandas import json_normalize\n",
        "\n",
        "json_normalize(response.result[\"results\"],\"alternatives\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzEtmnjrDegN",
        "outputId": "5b4ba1b5-0ff7-49dc-d95d-d4b71c263cf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x7ff87181dd90>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_ZQuvJEDegO",
        "outputId": "c602dd70-cff5-4b90-9b45-d38e596fbd48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ibm_cloud_sdk_core.detailed_response.DetailedResponse"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMkk0lWsDegO"
      },
      "source": [
        "<p>We can obtain the recognized text and assign it to the variable <code>recognized_text</code>:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "joPQgEKlDegP"
      },
      "outputs": [],
      "source": [
        "recognized_text=response.result['results'][0][\"alternatives\"][0][\"transcript\"]\n",
        "type(recognized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSUPO6KzDegP",
        "outputId": "67643903-ccb7-4699-ff5a-c6e8d2d78215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'in this video we will cover polynomial regression and pipelines '"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recognized_text=response.result[\"results\"][0][\"alternatives\"][0][\"transcript\"]\n",
        "print(type(recognized_text))\n",
        "recognized_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D63KIE0SDegP"
      },
      "source": [
        "<h2 id=\"ref1\">Language Translator</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwabwqUnDegQ"
      },
      "source": [
        "<p>First we import <code>LanguageTranslatorV3</code> from ibm_watson. For more information on the API click <a href=\"https://cloud.ibm.com/apidocs/speech-to-text?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01&code=python\"> here</a></p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzxjoI3tDegQ"
      },
      "outputs": [],
      "source": [
        "from ibm_watson import LanguageTranslatorV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr-aFeEEDegQ"
      },
      "outputs": [],
      "source": [
        "from ibm_watson import LanguageTranslatorV3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV-tnL07DegR"
      },
      "source": [
        "<p>The service endpoint is based on the location of the service instance, we store the information in the variable URL. To find out which URL to use, view the service credentials.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "PSXC350CDegR"
      },
      "outputs": [],
      "source": [
        "url_lt=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzBVkmVWDegR"
      },
      "outputs": [],
      "source": [
        "url_lt=\"https://api.eu-de.language-translator.watson.cloud.ibm.com/instances/fe3871fa-e8e4-48c5-8c49-e88bcc903bab\" #service endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfxwAniDegS"
      },
      "source": [
        "<p>You require an API key, and you can obtain the key on the <a href=\"https://cloud.ibm.com/resources?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01\">Dashboard</a>.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "w4L0QtH2DegS"
      },
      "outputs": [],
      "source": [
        "apikey_lt=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOLDAGcwDegb"
      },
      "outputs": [],
      "source": [
        "apikey_lt=\"wO3o7xT7mm38gapuax1ld24-FzQjfjfEkRsugFbydVc2\" #API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdKL4JqpDegb"
      },
      "source": [
        "<p>API requests require a version parameter that takes a date in the format version=YYYY-MM-DD. This lab describes the current version of Language Translator, 2018-05-01</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "gNToW_dyDegc"
      },
      "outputs": [],
      "source": [
        "version_lt='2018-05-01'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsSoBoQzDegc"
      },
      "outputs": [],
      "source": [
        "version_lt=\"2021-12-12\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5jDW7fCDegc"
      },
      "source": [
        "<p>we create a  Language Translator object <code>language_translator</code>:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-R6_CWiADegd"
      },
      "outputs": [],
      "source": [
        "authenticator = IAMAuthenticator(apikey_lt)\n",
        "language_translator = LanguageTranslatorV3(version=version_lt,authenticator=authenticator)\n",
        "language_translator.set_service_url(url_lt)\n",
        "language_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiRlU8qoDegd",
        "outputId": "b87dc503-7ea4-4962-cc35-7545363bcaa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ibm_watson.language_translator_v3.LanguageTranslatorV3 at 0x7ff85e6bd850>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Language Translator object\n",
        "authenticator = IAMAuthenticator(apikey_lt)\n",
        "language_translator = LanguageTranslatorV3(version=version_lt,authenticator=authenticator)\n",
        "language_translator.set_service_url(url_lt)\n",
        "language_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbZjdal5Degd",
        "outputId": "75d262cf-8efe-4ecc-aacf-d02f3218ca7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'languages': [{'language': 'af', 'name': 'Afrikaans'},\n",
              "  {'language': 'ar', 'name': 'Arabic'},\n",
              "  {'language': 'az', 'name': 'Azerbaijani'},\n",
              "  {'language': 'ba', 'name': 'Bashkir'},\n",
              "  {'language': 'be', 'name': 'Belarusian'},\n",
              "  {'language': 'bg', 'name': 'Bulgarian'},\n",
              "  {'language': 'bn', 'name': 'Bengali'},\n",
              "  {'language': 'ca', 'name': 'Catalan'},\n",
              "  {'language': 'cs', 'name': 'Czech'},\n",
              "  {'language': 'cv', 'name': 'Chuvash'},\n",
              "  {'language': 'cy', 'name': 'Welsh'},\n",
              "  {'language': 'da', 'name': 'Danish'},\n",
              "  {'language': 'de', 'name': 'German'},\n",
              "  {'language': 'el', 'name': 'Greek'},\n",
              "  {'language': 'en', 'name': 'English'},\n",
              "  {'language': 'eo', 'name': 'Esperanto'},\n",
              "  {'language': 'es', 'name': 'Spanish'},\n",
              "  {'language': 'et', 'name': 'Estonian'},\n",
              "  {'language': 'eu', 'name': 'Basque'},\n",
              "  {'language': 'fa', 'name': 'Persian'},\n",
              "  {'language': 'fi', 'name': 'Finnish'},\n",
              "  {'language': 'fr', 'name': 'French'},\n",
              "  {'language': 'ga', 'name': 'Irish'},\n",
              "  {'language': 'gu', 'name': 'Gujarati'},\n",
              "  {'language': 'he', 'name': 'Hebrew'},\n",
              "  {'language': 'hi', 'name': 'Hindi'},\n",
              "  {'language': 'hr', 'name': 'Croatian'},\n",
              "  {'language': 'ht', 'name': 'Haitian'},\n",
              "  {'language': 'hu', 'name': 'Hungarian'},\n",
              "  {'language': 'hy', 'name': 'Armenian'},\n",
              "  {'language': 'is', 'name': 'Icelandic'},\n",
              "  {'language': 'it', 'name': 'Italian'},\n",
              "  {'language': 'ja', 'name': 'Japanese'},\n",
              "  {'language': 'ka', 'name': 'Georgian'},\n",
              "  {'language': 'kk', 'name': 'Kazakh'},\n",
              "  {'language': 'km', 'name': 'Central Khmer'},\n",
              "  {'language': 'ko', 'name': 'Korean'},\n",
              "  {'language': 'ku', 'name': 'Kurdish'},\n",
              "  {'language': 'ky', 'name': 'Kirghiz'},\n",
              "  {'language': 'lo', 'name': 'Lao'},\n",
              "  {'language': 'lt', 'name': 'Lithuanian'},\n",
              "  {'language': 'lv', 'name': 'Latvian'},\n",
              "  {'language': 'ml', 'name': 'Malayalam'},\n",
              "  {'language': 'mn', 'name': 'Mongolian'},\n",
              "  {'language': 'mr', 'name': 'Marathi'},\n",
              "  {'language': 'ms', 'name': 'Malay'},\n",
              "  {'language': 'mt', 'name': 'Maltese'},\n",
              "  {'language': 'my', 'name': 'Burmese'},\n",
              "  {'language': 'nb', 'name': 'Norwegian Bokmal'},\n",
              "  {'language': 'ne', 'name': 'Nepali'},\n",
              "  {'language': 'nl', 'name': 'Dutch'},\n",
              "  {'language': 'nn', 'name': 'Norwegian Nynorsk'},\n",
              "  {'language': 'pa', 'name': 'Punjabi'},\n",
              "  {'language': 'pa-PK', 'name': 'Punjabi (Shahmukhi script, Pakistan)'},\n",
              "  {'language': 'pl', 'name': 'Polish'},\n",
              "  {'language': 'ps', 'name': 'Pushto'},\n",
              "  {'language': 'pt', 'name': 'Portuguese'},\n",
              "  {'language': 'ro', 'name': 'Romanian'},\n",
              "  {'language': 'ru', 'name': 'Russian'},\n",
              "  {'language': 'si', 'name': 'Sinhala'},\n",
              "  {'language': 'sk', 'name': 'Slovakian'},\n",
              "  {'language': 'sl', 'name': 'Slovenian'},\n",
              "  {'language': 'so', 'name': 'Somali'},\n",
              "  {'language': 'sq', 'name': 'Albanian'},\n",
              "  {'language': 'sr', 'name': 'Serbian'},\n",
              "  {'language': 'sv', 'name': 'Swedish'},\n",
              "  {'language': 'ta', 'name': 'Tamil'},\n",
              "  {'language': 'te', 'name': 'Telugu'},\n",
              "  {'language': 'th', 'name': 'Thai'},\n",
              "  {'language': 'tl', 'name': 'Tagalog'},\n",
              "  {'language': 'tr', 'name': 'Turkish'},\n",
              "  {'language': 'uk', 'name': 'Ukrainian'},\n",
              "  {'language': 'ur', 'name': 'Urdu'},\n",
              "  {'language': 'vi', 'name': 'Vietnamese'},\n",
              "  {'language': 'zh', 'name': 'Simplified Chinese'},\n",
              "  {'language': 'zh-TW', 'name': 'Traditional Chinese'}]}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "language_translator.list_identifiable_languages().get_result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSXLn6mlDege"
      },
      "source": [
        "<p>We can get a Lists the languages that the service can identify.\n",
        "The method Returns the language code.  For example English (en) to  Spanis (es) and name of each language.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "o1oyobvhDege"
      },
      "outputs": [],
      "source": [
        "from pandas import json_normalize\n",
        "\n",
        "json_normalize(language_translator.list_identifiable_languages().get_result(), \"languages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDZtqreZDege",
        "outputId": "aed70d8d-f07b-4de6-cca3-e1d005ea3ed4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>af</td>\n",
              "      <td>Afrikaans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>az</td>\n",
              "      <td>Azerbaijani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ba</td>\n",
              "      <td>Bashkir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>be</td>\n",
              "      <td>Belarusian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>uk</td>\n",
              "      <td>Ukrainian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>vi</td>\n",
              "      <td>Vietnamese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>zh</td>\n",
              "      <td>Simplified Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>zh-TW</td>\n",
              "      <td>Traditional Chinese</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   language                 name\n",
              "0        af            Afrikaans\n",
              "1        ar               Arabic\n",
              "2        az          Azerbaijani\n",
              "3        ba              Bashkir\n",
              "4        be           Belarusian\n",
              "..      ...                  ...\n",
              "71       uk            Ukrainian\n",
              "72       ur                 Urdu\n",
              "73       vi           Vietnamese\n",
              "74       zh   Simplified Chinese\n",
              "75    zh-TW  Traditional Chinese\n",
              "\n",
              "[76 rows x 2 columns]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pandas import json_normalize\n",
        "\n",
        "json_normalize(language_translator.list_identifiable_languages().get_result(),\"languages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fMgU7XkDegf"
      },
      "source": [
        "<p>We can use the method <code>translate</code>. This will translate the text. The parameter text is the text, Model_id is the type of model we would like to use use we use list the language. In this case, we set it to 'en-es' or English to Spanish. We get a Detailed Response object translation_response</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "WoBOTf7YDegf"
      },
      "outputs": [],
      "source": [
        "translation_response = language_translator.translate(\\\n",
        "    text=recognized_text, model_id='en-es')\n",
        "translation_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m23j4bJDegf",
        "outputId": "9dc15d57-585d-43bb-9072-a4a853906604"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['DEFAULT_SERVICE_NAME',\n",
              " 'DEFAULT_SERVICE_URL',\n",
              " 'ERROR_MSG_DISABLE_SSL',\n",
              " 'SDK_NAME',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_build_user_agent',\n",
              " '_convert_list',\n",
              " '_convert_model',\n",
              " '_encode_path_vars',\n",
              " '_get_system_info',\n",
              " '_set_user_agent_header',\n",
              " 'authenticator',\n",
              " 'configure_service',\n",
              " 'create_model',\n",
              " 'default_headers',\n",
              " 'delete_document',\n",
              " 'delete_model',\n",
              " 'disable_retries',\n",
              " 'disable_ssl_verification',\n",
              " 'enable_gzip_compression',\n",
              " 'enable_retries',\n",
              " 'encode_path_vars',\n",
              " 'get_authenticator',\n",
              " 'get_document_status',\n",
              " 'get_enable_gzip_compression',\n",
              " 'get_http_client',\n",
              " 'get_model',\n",
              " 'get_translated_document',\n",
              " 'http_adapter',\n",
              " 'http_client',\n",
              " 'http_config',\n",
              " 'identify',\n",
              " 'jar',\n",
              " 'list_documents',\n",
              " 'list_identifiable_languages',\n",
              " 'list_languages',\n",
              " 'list_models',\n",
              " 'prepare_request',\n",
              " 'retry_config',\n",
              " 'send',\n",
              " 'service_url',\n",
              " 'set_default_headers',\n",
              " 'set_disable_ssl_verification',\n",
              " 'set_enable_gzip_compression',\n",
              " 'set_http_client',\n",
              " 'set_http_config',\n",
              " 'set_service_url',\n",
              " 'translate',\n",
              " 'translate_document',\n",
              " 'user_agent_header',\n",
              " 'version']"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(language_translator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZA64q65Degg",
        "outputId": "2925d5f0-c591-45e0-853d-4c5a259d97ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x7ff85e8b6b50>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Time to translate English to Spanish\n",
        "\n",
        "translation_response=language_translator.translate(\\\n",
        "    text=recognized_text,model_id=\"en-es\")\n",
        "translation_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT3D0wm_Degg",
        "outputId": "7591344e-d1f6-42d3-83e6-8fea0de93a64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_to_dict',\n",
              " 'get_headers',\n",
              " 'get_result',\n",
              " 'get_status_code',\n",
              " 'headers',\n",
              " 'result',\n",
              " 'status_code']"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(translation_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdfu7iHdDegg"
      },
      "source": [
        "<p>The result is a dictionary.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "8aMuJkLpDegh"
      },
      "outputs": [],
      "source": [
        "translation=translation_response.get_result()\n",
        "translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYeKym_vDegh",
        "outputId": "be07f291-004a-4117-9a77-b49e0cdc853d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'translations': [{'translation': 'en este vídeo cubriremos la regresión polinómica y las tuberías '}],\n",
              " 'word_count': 10,\n",
              " 'character_count': 64}"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_response.result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qSp86UYDegh",
        "outputId": "8bf15c36-f331-491a-ce1b-580e1c36371a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'translations': [{'translation': 'en este vídeo cubriremos la regresión polinómica y las tuberías '}],\n",
              " 'word_count': 10,\n",
              " 'character_count': 64}"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_response.get_result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEUvJbSaDegh",
        "outputId": "23c96094-e061-435b-a085-0cfce2e65e0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'translations': [{'translation': 'en este vídeo cubriremos la regresión polinómica y las tuberías '}],\n",
              " 'word_count': 10,\n",
              " 'character_count': 64}"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation=translation_response.get_result()\n",
        "translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X41GkaemDegj"
      },
      "source": [
        "<p>We can obtain the actual translation as a string as follows:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVNnDPZ2Degj"
      },
      "outputs": [],
      "source": [
        "spanish_translation =translation['translations'][0]['translation']\n",
        "spanish_translation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzvqMd5kDegj",
        "outputId": "b48b3d5f-becd-4f48-d95c-1829f3d34c14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'en este vídeo cubriremos la regresión polinómica y las tuberías '"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spanish_translation=translation[\"translations\"][0][\"translation\"]#[0:10]\n",
        "spanish_translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18oZKJsQDegj"
      },
      "source": [
        "<p>We can translate back to English</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCk2NeZ-Degj"
      },
      "outputs": [],
      "source": [
        "translation_new = language_translator.translate(text=spanish_translation ,model_id='es-en').get_result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuHYTuMSDegj",
        "outputId": "85d761c3-8b77-42a0-d956-76c622ac10bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'translations': [{'translation': 'in this video we will cover the polynomial regression and the pipes '}],\n",
              " 'word_count': 10,\n",
              " 'character_count': 64}"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_new=language_translator.translate(text=spanish_translation,model_id=\"es-en\").get_result()\n",
        "translation_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CFymm_UDegj",
        "outputId": "70a3dc1e-197a-4dcc-c294-82246ee5a75d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(translation_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKwiKasJDegk",
        "outputId": "6ec6829e-e4ae-47b5-f666-f4115e902365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['translations', 'word_count', 'character_count'])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_new.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CACMoKEDegk",
        "outputId": "712d80d3-5c1c-42a3-f91e-82b75fba0791"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values([[{'translation': 'in this video we will cover the polynomial regression and the pipes '}], 10, 64])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_new.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrG1sziODegl",
        "outputId": "6f0d0067-96a5-4fba-df4e-ba5e072f68f3"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'keys'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_338/3937537656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslation_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"translations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
          ]
        }
      ],
      "source": [
        "translation_new[\"translations\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG5UfYCFDegl",
        "outputId": "3903c6f5-6809-474a-ce00-5b15299c0d62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(translation_new[\"translations\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbpLug8nDegm",
        "outputId": "791bbcf2-b965-4d84-a9e2-b948a01f8be4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(translation_new[\"translations\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ybHftUDDegn",
        "outputId": "dea3ce40-cd4d-43bb-e54d-34e7dc83bf35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'translation': 'in this video we will cover the polynomial regression and the pipes '}"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_new[\"translations\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE9qkYHdDegn",
        "outputId": "1e17d094-e95f-4677-b869-81518c2e4fca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(translation_new[\"translations\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsdovvRWDegn",
        "outputId": "a14d8b5f-b6b6-42a6-e7f4-6ad3e8d3aaee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['translation'])"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_new[\"translations\"][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OlYgVa8Dego",
        "outputId": "4a236b04-a1ab-4ae5-acd9-27ea37c014f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_values(['in this video we will cover the polynomial regression and the pipes '])"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_new[\"translations\"][0].values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESNMIcyIDego"
      },
      "source": [
        "<p>We can obtain the actual translation as a string as follows:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cosORhkkDegp"
      },
      "outputs": [],
      "source": [
        "translation_eng=translation_new['translations'][1]['translation']\n",
        "translation_eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCrPYvttDegp",
        "outputId": "5cebcd0f-821f-4e74-b935-0085ec620666"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'in this video we will cover the polynomial regression and the pipes '"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translation_eng=translation_new[\"translations\"][0][\"translation\"]\n",
        "translation_eng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFKuoJRgDegp"
      },
      "source": [
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLwzErM7Degq"
      },
      "source": [
        "<h2>Quiz</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zas4-zgEDegq"
      },
      "source": [
        "Translate to French.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVGvCnx0Degq",
        "outputId": "013c7df1-f3a4-489e-d0ea-8c043f9452a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Dans cette vidéo, nous couvrons la régression polynomiale et les pipelines '"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Write your code below and press Shift+Enter to execute\n",
        "translation_new_fr=language_translator.translate(text=recognized_text,model_id=\"en-fr\").get_result()\n",
        "translation_fr=translation_new_fr[\"translations\"][0][\"translation\"]\n",
        "translation_fr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ciuolrDegr"
      },
      "source": [
        "<details><summary>Click here for the solution</summary>\n",
        "\n",
        "```python\n",
        "French_translation=language_translator.translate(\n",
        "    text=translation_eng , model_id='en-fr').get_result()\n",
        "\n",
        "French_translation['translations'][0]['translation']\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_JRtu6EDegs"
      },
      "source": [
        "<h3>Language Translator</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA0v8FhDDegt"
      },
      "source": [
        "<b>References</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3KJKWJKDegt"
      },
      "source": [
        "[https://cloud.ibm.com/apidocs/speech-to-text?code=python](https://cloud.ibm.com/apidocs/speech-to-text?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01&code=python)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8LtV8AfDegv"
      },
      "source": [
        "[https://cloud.ibm.com/apidocs/language-translator?code=python](https://cloud.ibm.com/apidocs/language-translator?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01&code=python)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc5SP7WFDegv"
      },
      "source": [
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2JreskUDegv"
      },
      "source": [
        "## Authors:\n",
        "\n",
        "[Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01)\n",
        "\n",
        "Joseph Santarcangelo has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
        "\n",
        "## Other Contributor(s)\n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/fanjiang0619/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork19487395-2021-01-01\">Fan Jiang</a>\n",
        "\n",
        "## Change Log\n",
        "\n",
        "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n",
        "| ----------------- | ------- | ---------- | ---------------------------------- |\n",
        "| 2021-04-07        | 2.2     | Malika     | Updated the libraries              |\n",
        "| 2021-01-05        | 2.1     | Malika     | Added a library                    |\n",
        "| 2020-08-26        | 2.0     | Lavanya    | Moved lab to course repo in GitLab |\n",
        "|                   |         |            |                                    |\n",
        "|                   |         |            |                                    |\n",
        "\n",
        "<hr/>\n",
        "\n",
        "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "name": "PY0101EN-5.2_API_2-edited.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}